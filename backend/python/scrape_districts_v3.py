"""
Scraper v3: C√†o ƒê·∫¶Y ƒê·ª¶ 100% th·ª≠a ƒë·∫•t t·ª´ iLIS C√† Mau
=======================================================
Thu·∫≠t to√°n: Ph√¢n trang theo idthuadat (UUID) + sortBy + CQL_FILTER
Server h·ªó tr·ª£ maxFeatures l√™n t·ªõi 50,000 ‚Üí ch·ªâ c·∫ßn v√†i request/huy·ªán

5 huy·ªán/TP c√≥ d·ªØ li·ªáu chi ti·∫øt:
  1. C√°i N∆∞·ªõc    (~101,918 th·ª≠a)
  2. ƒê·∫ßm D∆°i     (~109,736 th·ª≠a)
  3. TP C√† Mau   (~146,708 th·ª≠a)
  4. Tr·∫ßn VƒÉn Th·ªùi (~131,329 th·ª≠a)
  5. U Minh      (~71,939 th·ª≠a)

S·ª≠ d·ª•ng:
  python scrape_districts_v3.py --district "C√°i N∆∞·ªõc"
  python scrape_districts_v3.py --all
  python scrape_districts_v3.py --check
  python scrape_districts_v3.py --clean "C√°i N∆∞·ªõc"
  python scrape_districts_v3.py --clean-all
  python scrape_districts_v3.py --summary
"""

import json
import sys
import time
import re
import argparse
import urllib.request
import urllib.error
import urllib.parse
import psycopg2
import psycopg2.extras

# ============= CONFIG =============
WFS_BASE_URL = "https://ilis-sdk.vnpt.vn/map/geoserver/iLIS_CMU/wfs"
BATCH_SIZE = 10000      # features per request (server supports up to 50K)
MAX_RETRIES = 4
RETRY_DELAY = 5
RATE_LIMIT = 0.3        # seconds between requests

DB_CONFIG = {
    "host": "localhost", "port": 5432,
    "dbname": "AgriPlanner", "user": "postgres", "password": "Kiet2004"
}
PROVINCE = "C√† Mau"

# ============= DISTRICTS =============
DISTRICTS = {
    "C√°i N∆∞·ªõc": {
        "layer": "iLIS_CMU:cmu_thuadat_huyencainuoc",
    },
    "ƒê·∫ßm D∆°i": {
        "layer": "iLIS_CMU:cmu_thuadat_huyendamdoi",
    },
    "TP C√† Mau": {
        "layer": "iLIS_CMU:cmu_thuadat_tpcamau",
    },
    "Tr·∫ßn VƒÉn Th·ªùi": {
        "layer": "iLIS_CMU:cmu_thuadat_huyentranvanthoi",
    },
    "U Minh": {
        "layer": "iLIS_CMU:cmu_thuadat_huyenuminh",
    },
}

# ============= LAND USE CODES =============
LAND_USE_MAP = {
    "LUC": "ƒê·∫•t chuy√™n tr·ªìng l√∫a n∆∞·ªõc", "LUK": "ƒê·∫•t tr·ªìng l√∫a n∆∞·ªõc c√≤n l·∫°i",
    "LUN": "ƒê·∫•t l√∫a n∆∞∆°ng", "LUA": "ƒê·∫•t tr·ªìng l√∫a",
    "CHN": "ƒê·∫•t tr·ªìng c√¢y h√†ng nƒÉm kh√°c", "BHK": "ƒê·∫•t b·∫±ng tr·ªìng c√¢y h√†ng nƒÉm kh√°c",
    "HNK": "ƒê·∫•t n∆∞∆°ng r·∫´y", "CLN": "ƒê·∫•t tr·ªìng c√¢y l√¢u nƒÉm",
    "RSX": "ƒê·∫•t r·ª´ng s·∫£n xu·∫•t", "RPH": "ƒê·∫•t r·ª´ng ph√≤ng h·ªô",
    "RDD": "ƒê·∫•t r·ª´ng ƒë·∫∑c d·ª•ng", "NTS": "ƒê·∫•t nu√¥i tr·ªìng th·ªßy s·∫£n",
    "LMU": "ƒê·∫•t l√†m mu·ªëi", "NKH": "ƒê·∫•t n√¥ng nghi·ªáp kh√°c",
    "ONT": "ƒê·∫•t ·ªü n√¥ng th√¥n", "ODT": "ƒê·∫•t ·ªü ƒë√¥ th·ªã",
    "TSC": "ƒê·∫•t tr·ª• s·ªü c∆° quan", "DGD": "ƒê·∫•t c∆° s·ªü gi√°o d·ª•c ƒë√†o t·∫°o",
    "DYT": "ƒê·∫•t c∆° s·ªü y t·∫ø", "DVH": "ƒê·∫•t c∆° s·ªü vƒÉn h√≥a",
    "DTT": "ƒê·∫•t c∆° s·ªü th·ªÉ d·ª•c th·ªÉ thao", "DGT": "ƒê·∫•t giao th√¥ng",
    "DTL": "ƒê·∫•t th·ªßy l·ª£i", "DNL": "ƒê·∫•t c√¥ng tr√¨nh nƒÉng l∆∞·ª£ng",
    "DBV": "ƒê·∫•t b∆∞u ch√≠nh vi·ªÖn th√¥ng",
    "SKC": "ƒê·∫•t c·ª•m khu c√¥ng nghi·ªáp", "SKK": "ƒê·∫•t khu kinh t·∫ø",
    "SKT": "ƒê·∫•t khu c√¥ng ngh·ªá cao", "TMD": "ƒê·∫•t th∆∞∆°ng m·∫°i d·ªãch v·ª•",
    "NTD": "ƒê·∫•t nghƒ©a trang, nh√† tang l·ªÖ",
    "SON": "ƒê·∫•t s√¥ng ng√≤i, k√™nh r·∫°ch, su·ªëi",
    "MNC": "ƒê·∫•t m·∫∑t n∆∞·ªõc chuy√™n d√πng", "PNK": "ƒê·∫•t phi n√¥ng nghi·ªáp kh√°c",
    "BCS": "ƒê·∫•t b·∫±ng ch∆∞a s·ª≠ d·ª•ng", "DCS": "ƒê·∫•t ƒë·ªìi ch∆∞a s·ª≠ d·ª•ng",
    "NCS": "N√∫i ƒë√° kh√¥ng c√≥ r·ª´ng c√¢y", "CSD": "ƒê·∫•t ch∆∞a s·ª≠ d·ª•ng",
    "TIN": "ƒê·∫•t t√¥n gi√°o", "CQP": "ƒê·∫•t qu·ªëc ph√≤ng", "CAN": "ƒê·∫•t an ninh",
    "DHT": "ƒê·∫•t h·∫° t·∫ßng", "DCH": "ƒê·∫•t ch·ª£", "DRA": "ƒê·∫•t b√£i th·∫£i",
    "SKX": "ƒê·∫•t s·∫£n xu·∫•t phi n√¥ng nghi·ªáp", "TSL": "ƒê·∫•t c√¢y th·ª±c l√¢m",
    "DKV": "ƒê·∫•t khu vui ch∆°i", "TON": "ƒê·∫•t t√¥n gi√°o",
    "LNK": "ƒê·∫•t l√¢m nghi·ªáp kh√°c", "DDT": "ƒê·∫•t ƒë√¥ th·ªã",
    "DSH": "ƒê·∫•t sinh ho·∫°t c·ªông ƒë·ªìng",
    "ONT+CLN": "ƒê·∫•t ·ªü + C√¢y l√¢u nƒÉm", "ODT+CLN": "ƒê·∫•t ·ªü ƒêT + C√¢y l√¢u nƒÉm",
    "CLN+LUK": "C√¢y l√¢u nƒÉm + L√∫a", "NTS+CLN": "Th·ªßy s·∫£n + C√¢y l√¢u nƒÉm",
    "LUK+CLN": "L√∫a + C√¢y l√¢u nƒÉm", "ONT+LUK": "ƒê·∫•t ·ªü + L√∫a",
    "CLN+NTS": "C√¢y l√¢u nƒÉm + Th·ªßy s·∫£n", "LUK+NTS": "L√∫a + Th·ªßy s·∫£n",
    "NTS+LUK": "Th·ªßy s·∫£n + L√∫a", "ODT+LNK": "ƒê·∫•t ·ªü ƒêT + L√¢m nghi·ªáp",
    "CLN+ODT": "C√¢y l√¢u nƒÉm + ·ªû ƒë√¥ th·ªã", "CLN+ONT": "C√¢y l√¢u nƒÉm + ·ªû n√¥ng th√¥n",
    "ODT+NTS": "ƒê·∫•t ·ªü ƒêT + Th·ªßy s·∫£n",
}


def lookup_land_use_name(code):
    if not code:
        return None
    code = code.strip()
    if code in LAND_USE_MAP:
        return LAND_USE_MAP[code]
    parts = code.replace("+", ",").replace("/", ",").split(",")
    names = [LAND_USE_MAP.get(p.strip(), p.strip()) for p in parts]
    return " + ".join(names) if names else code


def calculate_centroid(geometry):
    if not geometry or not geometry.get("coordinates"):
        return None, None
    all_coords = []

    def extract(c):
        if not c:
            return
        if isinstance(c, list) and len(c) >= 2 and isinstance(c[0], (int, float)):
            all_coords.append(c)
        elif isinstance(c, list):
            for item in c:
                extract(item)

    extract(geometry["coordinates"])
    if not all_coords:
        return None, None
    lngs = [c[0] for c in all_coords]
    lats = [c[1] for c in all_coords]
    return round(sum(lats) / len(lats), 7), round(sum(lngs) / len(lngs), 7)


# ============= WFS =============

def get_total_features(layer_name):
    url = (
        f"{WFS_BASE_URL}?SERVICE=WFS&VERSION=1.1.0&REQUEST=GetFeature"
        f"&typeName={layer_name}&resultType=hits"
    )
    for attempt in range(MAX_RETRIES):
        try:
            req = urllib.request.Request(url, headers={"User-Agent": "AgriPlanner/3"})
            r = urllib.request.urlopen(req, timeout=30)
            data = r.read().decode("utf-8")
            m = re.search(r'numberOfFeatures="(\d+)"', data)
            if m:
                return int(m.group(1))
        except Exception:
            time.sleep(RETRY_DELAY)
    return 0


def fetch_page(layer_name, after_id=None, batch_size=BATCH_SIZE):
    """Fetch a page of features sorted by idthuadat, optionally after a specific ID."""
    params = (
        f"SERVICE=WFS&VERSION=1.1.0&REQUEST=GetFeature"
        f"&typeName={layer_name}"
        f"&outputFormat=application/json"
        f"&srsName=EPSG:4326"
        f"&maxFeatures={batch_size}"
        f"&sortBy=idthuadat"
    )
    if after_id:
        cql = urllib.parse.quote(f"idthuadat>'{after_id}'")
        params += f"&CQL_FILTER={cql}"

    url = f"{WFS_BASE_URL}?{params}"

    for attempt in range(MAX_RETRIES):
        try:
            req = urllib.request.Request(url, headers={
                "User-Agent": "AgriPlanner/3", "Accept": "application/json"
            })
            r = urllib.request.urlopen(req, timeout=300)
            raw = r.read()
            if not raw or raw[0:1] == b'<':
                print(f"\n     ‚ö† XML response (attempt {attempt+1}), retrying...")
                time.sleep(RETRY_DELAY * (attempt + 1))
                continue
            data = json.loads(raw.decode("utf-8"))
            return data.get("features", [])
        except Exception as e:
            if attempt < MAX_RETRIES - 1:
                print(f"\n     ‚ö† Error: {e} (attempt {attempt+1}), retrying...")
                time.sleep(RETRY_DELAY * (attempt + 1))
            else:
                print(f"\n     ‚ùå Failed after {MAX_RETRIES} attempts: {e}")
    return []


# ============= DATABASE =============

def get_db_connection():
    conn = psycopg2.connect(**DB_CONFIG)
    conn.set_client_encoding("UTF8")
    return conn


def ensure_columns(conn):
    sqls = [
        "ALTER TABLE land_parcels ADD COLUMN IF NOT EXISTS raw_properties JSONB;",
        "ALTER TABLE land_parcels ADD COLUMN IF NOT EXISTS source_system VARCHAR(50) DEFAULT 'iLIS';",
        "ALTER TABLE land_parcels ADD COLUMN IF NOT EXISTS updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP;",
        "ALTER TABLE land_parcels ADD COLUMN IF NOT EXISTS owner_name VARCHAR(200);",
        "ALTER TABLE land_parcels ADD COLUMN IF NOT EXISTS owner_address TEXT;",
        "ALTER TABLE land_parcels ADD COLUMN IF NOT EXISTS certificate_number VARCHAR(100);",
        "ALTER TABLE land_parcels ADD COLUMN IF NOT EXISTS certificate_date DATE;",
    ]
    for sql in sqls:
        try:
            cur = conn.cursor()
            cur.execute(sql)
            conn.commit()
            cur.close()
        except Exception:
            conn.rollback()


def get_district_count(conn, district_name):
    cur = conn.cursor()
    cur.execute("SELECT COUNT(*) FROM land_parcels WHERE district = %s", (district_name,))
    c = cur.fetchone()[0]
    cur.close()
    return c


def delete_district_data(conn, district_name):
    cur = conn.cursor()
    cur.execute("DELETE FROM land_parcels WHERE district = %s", (district_name,))
    d = cur.rowcount
    conn.commit()
    cur.close()
    return d


def get_last_parcel_id(conn, district_name):
    """Get the last (max) parcel_id for resume support."""
    cur = conn.cursor()
    cur.execute(
        "SELECT MAX(parcel_id) FROM land_parcels WHERE district = %s AND parcel_id IS NOT NULL",
        (district_name,)
    )
    row = cur.fetchone()
    cur.close()
    return row[0] if row and row[0] else None


def insert_batch(conn, features, district_name):
    if not features:
        return 0

    sql = """
        INSERT INTO land_parcels (
            object_id, parcel_id, map_sheet_id,
            map_sheet_number, parcel_number,
            area_sqm, legal_area_sqm,
            land_use_code, land_use_name,
            address, street_name, road, road_section, location,
            admin_unit_code, admin_unit_name, district, province,
            registration_status, change_status, spatial_status,
            area_zone, province_code,
            area_road, area_land, area_river, area_railway,
            boundary_geojson, center_lat, center_lng,
            notes, source_system, raw_properties
        ) VALUES (
            %(object_id)s, %(parcel_id)s, %(map_sheet_id)s,
            %(map_sheet_number)s, %(parcel_number)s,
            %(area_sqm)s, %(legal_area_sqm)s,
            %(land_use_code)s, %(land_use_name)s,
            %(address)s, %(street_name)s, %(road)s, %(road_section)s, %(location)s,
            %(admin_unit_code)s, %(admin_unit_name)s, %(district)s, %(province)s,
            %(registration_status)s, %(change_status)s, %(spatial_status)s,
            %(area_zone)s, %(province_code)s,
            %(area_road)s, %(area_land)s, %(area_river)s, %(area_railway)s,
            %(boundary_geojson)s, %(center_lat)s, %(center_lng)s,
            %(notes)s, 'iLIS', %(raw_properties)s
        )
        ON CONFLICT (parcel_id) WHERE parcel_id IS NOT NULL DO NOTHING
    """

    inserted = 0
    skipped = 0
    cur = conn.cursor()

    for f in features:
        props = f.get("properties", {})
        geom = f.get("geometry")
        parcel_id = props.get("idthuadat")
        if not parcel_id:
            skipped += 1
            continue

        center_lat, center_lng = calculate_centroid(geom)
        lc = (props.get("loaidat") or "").strip()

        row = {
            "object_id": props.get("objectid"),
            "parcel_id": parcel_id,
            "map_sheet_id": props.get("idtobando"),
            "map_sheet_number": props.get("tobandoso"),
            "parcel_number": props.get("sothututhua"),
            "area_sqm": props.get("dientich"),
            "legal_area_sqm": props.get("dientichpl"),
            "land_use_code": lc or None,
            "land_use_name": lookup_land_use_name(lc),
            "address": props.get("diachithua"),
            "street_name": props.get("tenduong"),
            "road": props.get("duong"),
            "road_section": props.get("doanduong"),
            "location": props.get("vitri"),
            "admin_unit_code": props.get("madvhc"),
            "admin_unit_name": props.get("tendvhc"),
            "district": district_name,
            "province": PROVINCE,
            "registration_status": props.get("trangthaidangky"),
            "change_status": props.get("trangthaibiendong"),
            "spatial_status": props.get("trangthaikhonggian"),
            "area_zone": props.get("khuvuc"),
            "province_code": props.get("parmatinh"),
            "area_road": props.get("dientichhlgt"),
            "area_land": props.get("dientichhlld"),
            "area_river": props.get("dientichhlsongsuoi"),
            "area_railway": props.get("dientichhlduongsat"),
            "boundary_geojson": json.dumps(geom) if geom else None,
            "center_lat": center_lat,
            "center_lng": center_lng,
            "notes": props.get("ghichu"),
            "raw_properties": json.dumps(props),
        }

        try:
            cur.execute("SAVEPOINT sp")
            cur.execute(sql, row)
            if cur.rowcount > 0:
                inserted += 1
            cur.execute("RELEASE SAVEPOINT sp")
        except Exception:
            cur.execute("ROLLBACK TO SAVEPOINT sp")

    conn.commit()
    cur.close()
    return inserted


# ============= MAIN SCRAPING =============

def scrape_district(conn, name, config):
    layer = config["layer"]

    print(f"\n{'='*65}")
    print(f"  üó∫Ô∏è  {name}")
    print(f"  üì° {layer}")
    print(f"{'='*65}")

    print(f"\n  üìä ƒê·∫øm features tr√™n server...")
    total_server = get_total_features(layer)
    if total_server == 0:
        print(f"  ‚ùå Layer r·ªóng ho·∫∑c kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c.")
        return 0, 0
    print(f"     Server: {total_server:,}")

    existing = get_district_count(conn, name)
    print(f"     DB:     {existing:,}")

    if existing >= total_server * 0.99:
        pct = existing / total_server * 100
        print(f"  ‚úÖ ƒê√£ ƒë·ªß ({pct:.1f}%).")
        return existing, 0

    # Resume support: get last parcel_id
    last_id = get_last_parcel_id(conn, name)
    if last_id:
        print(f"  ‚Ü©Ô∏è  Resume t·ª´: {last_id}")
    else:
        print(f"  üÜï B·∫Øt ƒë·∫ßu t·ª´ ƒë·∫ßu")

    print(f"\n  üîÑ Ph√¢n trang theo idthuadat...")
    print(f"     Batch size: {BATCH_SIZE:,}")
    print()

    start_time = time.time()
    total_fetched = 0
    total_inserted = 0
    page = 0
    after_id = last_id  # Resume from last ID

    while True:
        page += 1
        features = fetch_page(layer, after_id, BATCH_SIZE)

        if not features:
            print(f"\n     ‚úì Kh√¥ng c√≤n features (trang {page})")
            break

        # Get the last idthuadat for next page
        last_feat_id = None
        for f in reversed(features):
            lid = f.get("properties", {}).get("idthuadat")
            if lid:
                last_feat_id = lid
                break

        total_fetched += len(features)
        ins = insert_batch(conn, features, name)
        total_inserted += ins

        current_db = existing + total_inserted
        pct = current_db / total_server * 100 if total_server > 0 else 0
        elapsed = time.time() - start_time
        rate = total_inserted / elapsed if elapsed > 0 else 0

        sys.stdout.write(
            f"\r     Trang {page:>3}: "
            f"fetch={len(features):>6,} | "
            f"new={ins:>6,} | "
            f"total={current_db:>8,}/{total_server:,} ({pct:>5.1f}%) | "
            f"{rate:>5.0f}/s  "
        )
        sys.stdout.flush()

        if len(features) < BATCH_SIZE:
            print(f"\n     ‚úì Trang cu·ªëi (< batch_size)")
            break

        if last_feat_id:
            after_id = last_feat_id
        else:
            print(f"\n     ‚ö† Kh√¥ng t√¨m th·∫•y idthuadat trong batch cu·ªëi")
            break

        time.sleep(RATE_LIMIT)

    elapsed = time.time() - start_time
    final = get_district_count(conn, name)
    pct = final / total_server * 100 if total_server > 0 else 0

    print()
    print(f"\n  {'‚îÄ'*60}")
    print(f"  ‚úÖ {name}")
    print(f"     Fetched:   {total_fetched:,}")
    print(f"     Inserted:  {total_inserted:,}")
    print(f"     DB total:  {final:,}/{total_server:,} ({pct:.1f}%)")
    print(f"     Pages:     {page}")
    print(f"     Time:      {int(elapsed//60)}m{int(elapsed%60)}s")
    print(f"  {'‚îÄ'*60}")
    return final, total_inserted


def print_stats(conn, name):
    cur = conn.cursor()
    print(f"\n  üìä Lo·∫°i ƒë·∫•t ({name}):")
    cur.execute("""
        SELECT land_use_code, land_use_name, COUNT(*), ROUND(SUM(area_sqm)::numeric/10000, 2)
        FROM land_parcels WHERE district = %s
        GROUP BY land_use_code, land_use_name ORDER BY 3 DESC LIMIT 15
    """, (name,))
    print(f"     {'M√£':<12} {'T√™n':<35} {'Th·ª≠a':>8} {'DT(ha)':>12}")
    print(f"     {'-'*12} {'-'*35} {'-'*8} {'-'*12}")
    for c, n, cnt, ha in cur.fetchall():
        print(f"     {(c or '?'):<12} {(n or c or '?')[:35]:<35} {cnt:>8,} {(f'{ha:,.2f}' if ha else 'N/A'):>12}")

    print(f"\n  üìä X√£/Ph∆∞·ªùng ({name}):")
    cur.execute("""
        SELECT admin_unit_name, COUNT(*), ROUND(SUM(area_sqm)::numeric/10000, 2)
        FROM land_parcels WHERE district = %s
        GROUP BY admin_unit_name ORDER BY 2 DESC
    """, (name,))
    print(f"     {'X√£/Ph∆∞·ªùng':<30} {'Th·ª≠a':>8} {'DT(ha)':>12}")
    print(f"     {'-'*30} {'-'*8} {'-'*12}")
    for n, cnt, ha in cur.fetchall():
        print(f"     {(n or '?'):<30} {cnt:>8,} {(f'{ha:,.2f}' if ha else 'N/A'):>12}")
    cur.close()


def print_summary(conn):
    cur = conn.cursor()
    print(f"\n{'='*65}")
    print(f"  üìä T·ªîNG K·∫æT TO√ÄN T·ªàNH C√Ä MAU")
    print(f"{'='*65}")
    cur.execute("""
        SELECT district, COUNT(*), ROUND(SUM(area_sqm)::numeric/10000, 2)
        FROM land_parcels WHERE province = %s GROUP BY district ORDER BY 2 DESC
    """, (PROVINCE,))
    rows = cur.fetchall()
    print(f"\n  {'Huy·ªán/TP':<25} {'Th·ª≠a':>10} {'DT(ha)':>12}")
    print(f"  {'-'*25} {'-'*10} {'-'*12}")
    gt, gh = 0, 0
    for n, c, h in rows:
        hv = h or 0
        print(f"  {(n or '?'):<25} {c:>10,} {(f'{hv:,.2f}' if h else 'N/A'):>12}")
        gt += c; gh += hv
    print(f"  {'-'*25} {'-'*10} {'-'*12}")
    print(f"  {'T·ªîNG':<25} {gt:>10,} {gh:>12,.2f}")

    print(f"\n  üìä Top 10 lo·∫°i ƒë·∫•t:")
    cur.execute("""
        SELECT land_use_code, land_use_name, COUNT(*), ROUND(SUM(area_sqm)::numeric/10000, 2)
        FROM land_parcels WHERE province = %s GROUP BY 1, 2 ORDER BY 3 DESC LIMIT 10
    """, (PROVINCE,))
    print(f"  {'M√£':<10} {'T√™n':<35} {'Th·ª≠a':>8} {'DT(ha)':>12}")
    print(f"  {'-'*10} {'-'*35} {'-'*8} {'-'*12}")
    for c, n, cnt, ha in cur.fetchall():
        print(f"  {(c or '?'):<10} {(n or c or '?')[:35]:<35} {cnt:>8,} {(f'{ha:,.2f}' if ha else 'N/A'):>12}")
    cur.close()


# ============= MAIN =============

def main():
    p = argparse.ArgumentParser(description="Scraper v3: idthuadat pagination ‚Äî 100% coverage")
    p.add_argument("--district", type=str)
    p.add_argument("--all", action="store_true")
    p.add_argument("--check", action="store_true")
    p.add_argument("--clean", type=str)
    p.add_argument("--clean-all", action="store_true")
    p.add_argument("--summary", action="store_true")
    args = p.parse_args()

    conn = get_db_connection()
    ensure_columns(conn)

    if args.check:
        print(f"\n{'='*80}")
        print(f"  üìä TR·∫†NG TH√ÅI")
        print(f"{'='*80}")
        print(f"  {'Huy·ªán/TP':<20} {'Layer':<48} {'DB':>8} {'Server':>8} {'%':>6}")
        print(f"  {'-'*20} {'-'*48} {'-'*8} {'-'*8} {'-'*6}")
        all_d = {"Th·ªõi B√¨nh": {"layer": "iLIS_CMU:cmu_thuadat_huyenthoibinh"}}
        all_d.update(DISTRICTS)
        for n, c in all_d.items():
            db = get_district_count(conn, n)
            sv = get_total_features(c["layer"])
            pct = db/sv*100 if sv > 0 else 0
            i = "‚úÖ" if pct > 95 else ("üî∂" if pct > 50 else ("üî∑" if pct > 0 else "‚¨ú"))
            print(f"  {i} {n:<18} {c['layer']:<48} {db:>8,} {sv:>8,} {pct:>5.1f}%")
        conn.close()
        return

    if args.clean:
        matched = None
        for n in list(DISTRICTS.keys()) + ["Ph√∫ T√¢n", "Th·ªõi B√¨nh"]:
            if args.clean.lower() in n.lower():
                matched = n
                break
        if matched:
            d = delete_district_data(conn, matched)
            print(f"  üóëÔ∏è  X√≥a {d:,} records {matched}")
        else:
            print(f"  ‚ùå Kh√¥ng t√¨m '{args.clean}'")
        conn.close()
        return

    if args.clean_all:
        print(f"\n  üóëÔ∏è  X√≥a d·ªØ li·ªáu c≈© 5 huy·ªán + Ph√∫ T√¢n...")
        for n in list(DISTRICTS.keys()) + ["Ph√∫ T√¢n"]:
            d = delete_district_data(conn, n)
            print(f"     {n:<20} ‚Üí {d:,}")
        conn.close()
        return

    if args.summary:
        print_summary(conn)
        conn.close()
        return

    if args.district:
        matched = None
        for n in DISTRICTS:
            if args.district.lower() in n.lower():
                matched = n
                break
        if not matched:
            print(f"  ‚ùå Kh√¥ng t√¨m '{args.district}'. C√≥: {', '.join(DISTRICTS.keys())}")
            conn.close()
            return
        print("\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
        print("‚ïë  üó∫Ô∏è  SCRAPER V3 ‚Äî IDTHUADAT PAGINATION ‚Äî 100% COVERAGE     ‚ïë")
        print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")
        scrape_district(conn, matched, DISTRICTS[matched])
        print_stats(conn, matched)
        conn.close()
        return

    if args.all:
        print("\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
        print("‚ïë  üó∫Ô∏è  SCRAPER V3 ‚Äî TO√ÄN B·ªò 5 HUY·ªÜN ‚Äî 100% COVERAGE         ‚ïë")
        print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")
        start = time.time()
        results = {}
        for idx, (n, c) in enumerate(DISTRICTS.items(), 1):
            print(f"\n{'‚ñì'*65}")
            print(f"  [{idx}/{len(DISTRICTS)}] {n}")
            print(f"{'‚ñì'*65}")
            try:
                t, nw = scrape_district(conn, n, c)
                results[n] = {"total": t, "new": nw, "s": "‚úÖ"}
                print_stats(conn, n)
            except KeyboardInterrupt:
                print(f"\n  ‚ö† D·ª´ng t·∫°i {n}")
                results[n] = {"total": get_district_count(conn, n), "new": 0, "s": "‚ö†Ô∏è"}
                break
            except Exception as e:
                print(f"\n  ‚ùå {e}")
                import traceback
                traceback.print_exc()
                results[n] = {"total": get_district_count(conn, n), "new": 0, "s": "‚ùå"}

        el = time.time() - start
        print(f"\n{'='*65}")
        print(f"  üìä K·∫æT QU·∫¢ T·ªîNG H·ª¢P")
        print(f"{'='*65}")
        print(f"  {'Huy·ªán/TP':<20} {'':>4} {'DB':>10} {'M·ªõi':>8}")
        print(f"  {'-'*20} {'-'*4} {'-'*10} {'-'*8}")
        for n, r in results.items():
            print(f"  {n:<20} {r['s']:>4} {r['total']:>10,} {r['new']:>8,}")
        print(f"\n  ‚è± T·ªïng: {int(el//60)}m{int(el%60)}s")
        print_summary(conn)
        conn.close()
        return

    p.print_help()


if __name__ == "__main__":
    main()
